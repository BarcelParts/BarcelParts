{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.OrderedBulkOperation = void 0;\n\nconst BSON = require(\"../bson\");\n\nconst error_1 = require(\"../error\");\n\nconst common_1 = require(\"./common\");\n/** @public */\n\n\nclass OrderedBulkOperation extends common_1.BulkOperationBase {\n  constructor(collection, options) {\n    super(collection, options, true);\n  }\n\n  addToOperationsList(batchType, document) {\n    // Get the bsonSize\n    const bsonSize = BSON.calculateObjectSize(document, {\n      checkKeys: false,\n      // Since we don't know what the user selected for BSON options here,\n      // err on the safe side, and check the size with ignoreUndefined: false.\n      ignoreUndefined: false\n    }); // Throw error if the doc is bigger than the max BSON size\n\n    if (bsonSize >= this.s.maxBsonObjectSize) // TODO(NODE-3483): Change this to MongoBSONError\n      throw new error_1.MongoInvalidArgumentError(`Document is larger than the maximum size ${this.s.maxBsonObjectSize}`); // Create a new batch object if we don't have a current one\n\n    if (this.s.currentBatch == null) {\n      this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n    }\n\n    const maxKeySize = this.s.maxKeySize; // Check if we need to create a new batch\n\n    if ( // New batch if we exceed the max batch op size\n    this.s.currentBatchSize + 1 >= this.s.maxWriteBatchSize || // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n    // since we can't sent an empty batch\n    this.s.currentBatchSize > 0 && this.s.currentBatchSizeBytes + maxKeySize + bsonSize >= this.s.maxBatchSizeBytes || // New batch if the new op does not have the same op type as the current batch\n    this.s.currentBatch.batchType !== batchType) {\n      // Save the batch to the execution stack\n      this.s.batches.push(this.s.currentBatch); // Create a new batch\n\n      this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex); // Reset the current size trackers\n\n      this.s.currentBatchSize = 0;\n      this.s.currentBatchSizeBytes = 0;\n    }\n\n    if (batchType === common_1.BatchType.INSERT) {\n      this.s.bulkResult.insertedIds.push({\n        index: this.s.currentIndex,\n        _id: document._id\n      });\n    } // We have an array of documents\n\n\n    if (Array.isArray(document)) {\n      throw new error_1.MongoInvalidArgumentError('Operation passed in cannot be an Array');\n    }\n\n    this.s.currentBatch.originalIndexes.push(this.s.currentIndex);\n    this.s.currentBatch.operations.push(document);\n    this.s.currentBatchSize += 1;\n    this.s.currentBatchSizeBytes += maxKeySize + bsonSize;\n    this.s.currentIndex += 1;\n    return this;\n  }\n\n}\n\nexports.OrderedBulkOperation = OrderedBulkOperation;","map":{"version":3,"mappings":";;;;;;;AACA;;AAEA;;AAGA;AAEA;;;AACA,MAAaA,oBAAb,SAA0CC,0BAA1C,CAA2D;AACzDC,cAAYC,UAAZ,EAAoCC,OAApC,EAA6D;AAC3D,UAAMD,UAAN,EAAkBC,OAAlB,EAA2B,IAA3B;AACD;;AAEDC,qBAAmB,CACjBC,SADiB,EAEjBC,QAFiB,EAEqC;AAEtD;AACA,UAAMC,QAAQ,GAAGC,IAAI,CAACC,mBAAL,CAAyBH,QAAzB,EAAmC;AAClDI,eAAS,EAAE,KADuC;AAElD;AACA;AACAC,qBAAe,EAAE;AAJiC,KAAnC,CAAjB,CAHsD,CAUtD;;AACA,QAAIJ,QAAQ,IAAI,KAAKK,CAAL,CAAOC,iBAAvB,EACE;AACA,YAAM,IAAIC,iCAAJ,CACJ,4CAA4C,KAAKF,CAAL,CAAOC,iBAAiB,EADhE,CAAN,CAboD,CAiBtD;;AACA,QAAI,KAAKD,CAAL,CAAOG,YAAP,IAAuB,IAA3B,EAAiC;AAC/B,WAAKH,CAAL,CAAOG,YAAP,GAAsB,IAAIf,cAAJ,CAAUK,SAAV,EAAqB,KAAKO,CAAL,CAAOI,YAA5B,CAAtB;AACD;;AAED,UAAMC,UAAU,GAAG,KAAKL,CAAL,CAAOK,UAA1B,CAtBsD,CAwBtD;;AACA,SACE;AACA,SAAKL,CAAL,CAAOM,gBAAP,GAA0B,CAA1B,IAA+B,KAAKN,CAAL,CAAOO,iBAAtC,IACA;AACA;AACC,SAAKP,CAAL,CAAOM,gBAAP,GAA0B,CAA1B,IACC,KAAKN,CAAL,CAAOQ,qBAAP,GAA+BH,UAA/B,GAA4CV,QAA5C,IAAwD,KAAKK,CAAL,CAAOS,iBAJjE,IAKA;AACA,SAAKT,CAAL,CAAOG,YAAP,CAAoBV,SAApB,KAAkCA,SARpC,EASE;AACA;AACA,WAAKO,CAAL,CAAOU,OAAP,CAAeC,IAAf,CAAoB,KAAKX,CAAL,CAAOG,YAA3B,EAFA,CAIA;;AACA,WAAKH,CAAL,CAAOG,YAAP,GAAsB,IAAIf,cAAJ,CAAUK,SAAV,EAAqB,KAAKO,CAAL,CAAOI,YAA5B,CAAtB,CALA,CAOA;;AACA,WAAKJ,CAAL,CAAOM,gBAAP,GAA0B,CAA1B;AACA,WAAKN,CAAL,CAAOQ,qBAAP,GAA+B,CAA/B;AACD;;AAED,QAAIf,SAAS,KAAKL,mBAAUwB,MAA5B,EAAoC;AAClC,WAAKZ,CAAL,CAAOa,UAAP,CAAkBC,WAAlB,CAA8BH,IAA9B,CAAmC;AACjCI,aAAK,EAAE,KAAKf,CAAL,CAAOI,YADmB;AAEjCY,WAAG,EAAGtB,QAAqB,CAACsB;AAFK,OAAnC;AAID,KAnDqD,CAqDtD;;;AACA,QAAIC,KAAK,CAACC,OAAN,CAAcxB,QAAd,CAAJ,EAA6B;AAC3B,YAAM,IAAIQ,iCAAJ,CAA8B,wCAA9B,CAAN;AACD;;AAED,SAAKF,CAAL,CAAOG,YAAP,CAAoBgB,eAApB,CAAoCR,IAApC,CAAyC,KAAKX,CAAL,CAAOI,YAAhD;AACA,SAAKJ,CAAL,CAAOG,YAAP,CAAoBiB,UAApB,CAA+BT,IAA/B,CAAoCjB,QAApC;AACA,SAAKM,CAAL,CAAOM,gBAAP,IAA2B,CAA3B;AACA,SAAKN,CAAL,CAAOQ,qBAAP,IAAgCH,UAAU,GAAGV,QAA7C;AACA,SAAKK,CAAL,CAAOI,YAAP,IAAuB,CAAvB;AACA,WAAO,IAAP;AACD;;AAvEwD;;AAA3DiB","names":["OrderedBulkOperation","common_1","constructor","collection","options","addToOperationsList","batchType","document","bsonSize","BSON","calculateObjectSize","checkKeys","ignoreUndefined","s","maxBsonObjectSize","error_1","currentBatch","currentIndex","maxKeySize","currentBatchSize","maxWriteBatchSize","currentBatchSizeBytes","maxBatchSizeBytes","batches","push","INSERT","bulkResult","insertedIds","index","_id","Array","isArray","originalIndexes","operations","exports"],"sources":["D:\\Barcelparts\\node_modules\\mongodb\\src\\bulk\\ordered.ts"],"sourcesContent":["import type { Document } from '../bson';\nimport * as BSON from '../bson';\nimport type { Collection } from '../collection';\nimport { MongoInvalidArgumentError } from '../error';\nimport type { DeleteStatement } from '../operations/delete';\nimport type { UpdateStatement } from '../operations/update';\nimport { Batch, BatchType, BulkOperationBase, BulkWriteOptions } from './common';\n\n/** @public */\nexport class OrderedBulkOperation extends BulkOperationBase {\n  constructor(collection: Collection, options: BulkWriteOptions) {\n    super(collection, options, true);\n  }\n\n  addToOperationsList(\n    batchType: BatchType,\n    document: Document | UpdateStatement | DeleteStatement\n  ): this {\n    // Get the bsonSize\n    const bsonSize = BSON.calculateObjectSize(document, {\n      checkKeys: false,\n      // Since we don't know what the user selected for BSON options here,\n      // err on the safe side, and check the size with ignoreUndefined: false.\n      ignoreUndefined: false\n    } as any);\n\n    // Throw error if the doc is bigger than the max BSON size\n    if (bsonSize >= this.s.maxBsonObjectSize)\n      // TODO(NODE-3483): Change this to MongoBSONError\n      throw new MongoInvalidArgumentError(\n        `Document is larger than the maximum size ${this.s.maxBsonObjectSize}`\n      );\n\n    // Create a new batch object if we don't have a current one\n    if (this.s.currentBatch == null) {\n      this.s.currentBatch = new Batch(batchType, this.s.currentIndex);\n    }\n\n    const maxKeySize = this.s.maxKeySize;\n\n    // Check if we need to create a new batch\n    if (\n      // New batch if we exceed the max batch op size\n      this.s.currentBatchSize + 1 >= this.s.maxWriteBatchSize ||\n      // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n      // since we can't sent an empty batch\n      (this.s.currentBatchSize > 0 &&\n        this.s.currentBatchSizeBytes + maxKeySize + bsonSize >= this.s.maxBatchSizeBytes) ||\n      // New batch if the new op does not have the same op type as the current batch\n      this.s.currentBatch.batchType !== batchType\n    ) {\n      // Save the batch to the execution stack\n      this.s.batches.push(this.s.currentBatch);\n\n      // Create a new batch\n      this.s.currentBatch = new Batch(batchType, this.s.currentIndex);\n\n      // Reset the current size trackers\n      this.s.currentBatchSize = 0;\n      this.s.currentBatchSizeBytes = 0;\n    }\n\n    if (batchType === BatchType.INSERT) {\n      this.s.bulkResult.insertedIds.push({\n        index: this.s.currentIndex,\n        _id: (document as Document)._id\n      });\n    }\n\n    // We have an array of documents\n    if (Array.isArray(document)) {\n      throw new MongoInvalidArgumentError('Operation passed in cannot be an Array');\n    }\n\n    this.s.currentBatch.originalIndexes.push(this.s.currentIndex);\n    this.s.currentBatch.operations.push(document);\n    this.s.currentBatchSize += 1;\n    this.s.currentBatchSizeBytes += maxKeySize + bsonSize;\n    this.s.currentIndex += 1;\n    return this;\n  }\n}\n"]},"metadata":{},"sourceType":"script"}